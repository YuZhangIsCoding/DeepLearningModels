{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(-1, 28, 28, 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape(-1, 28, 28, 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (train_images-127.5)/127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y=None, batch_size=32, epochs=1, shuffle=True):\n",
    "    if y is None:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(x))\n",
    "    dataset = dataset.batch(batch_size).repeat(epochs)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape\n",
    "from keras.layers import Conv2DTranspose, Conv2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "\n",
    "noise = tf.placeholder(tf.float32, shape=[None, noise_dim])\n",
    "targets = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same',\n",
    "                              use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('generator'):\n",
    "    generator = make_generator_model()\n",
    "    generated_images = generator(noise)\n",
    "with tf.name_scope('discriminator'):\n",
    "    discriminator = make_discriminator_model()\n",
    "    generated_logits = discriminator(generated_images)\n",
    "    target_logits = discriminator(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The generator loss \n",
    "\n",
    "Since we want the generator to generate pictures close to real pictures, we need to optimize the generator parameters so that the discrimintor think those generated pictures are real picture, which means the discriminator outputs 1 for the generated pictures. Thus the generator loss is a sigmoid cross entropy loss of the generated images and an array of ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator_loss\n",
    "gen_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(generated_logits),\n",
    "                                                  logits=generated_logits)\n",
    "gen_loss = tf.reduce_mean(gen_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The discriminator loss\n",
    "\n",
    "We want the discriminators able to distinguish fake images from real images. Fake images should be labeled as zeros, and real images should be labeled as ones. And combined the two erros together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_error = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(target_logits),\n",
    "                                                    logits=target_logits)\n",
    "fake_error = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(generated_logits),\n",
    "                                                    logits=generated_logits)\n",
    "real_error = tf.reduce_mean(real_error)\n",
    "fake_error = tf.reduce_mean(fake_error)\n",
    "dis_loss = real_error+fake_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_var_list = tf.trainable_variables(scope='generator')\n",
    "dis_var_list = tf.trainable_variables(scope='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_grads = tf.gradients(gen_loss, gen_var_list)\n",
    "dis_grads = tf.gradients(dis_loss, dis_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = tf.train.AdamOptimizer(1e-4).apply_gradients(zip(gen_grads, gen_var_list))\n",
    "dis_train = tf.train.AdamOptimizer(1e-4).apply_gradients(zip(dis_grads, dis_var_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, generator loss: 0.692550, discriminator loss: 1.383406\n",
      "Iteration 100, generator loss: 0.502349, discriminator loss: 1.192763\n",
      "Iteration 200, generator loss: 1.636345, discriminator loss: 0.596447\n",
      "Iteration 300, generator loss: 1.159016, discriminator loss: 0.869216\n",
      "Iteration 400, generator loss: 0.971280, discriminator loss: 1.271450\n",
      "Iteration 500, generator loss: 1.111439, discriminator loss: 1.635183\n",
      "Iteration 600, generator loss: 1.645658, discriminator loss: 0.592239\n",
      "Iteration 700, generator loss: 1.314601, discriminator loss: 1.103094\n",
      "Iteration 800, generator loss: 3.179282, discriminator loss: 0.115883\n",
      "Iteration 900, generator loss: 2.022287, discriminator loss: 0.511514\n",
      "Iteration 1000, generator loss: 1.909041, discriminator loss: 0.845537\n",
      "Iteration 1100, generator loss: 2.175731, discriminator loss: 0.456648\n",
      "Iteration 1200, generator loss: 1.755713, discriminator loss: 0.723967\n",
      "Iteration 1300, generator loss: 2.674845, discriminator loss: 0.288647\n",
      "Iteration 1400, generator loss: 1.945008, discriminator loss: 0.615020\n",
      "Iteration 1500, generator loss: 2.223220, discriminator loss: 0.630973\n",
      "Iteration 1600, generator loss: 1.609034, discriminator loss: 0.490034\n",
      "Iteration 1700, generator loss: 2.009838, discriminator loss: 0.852753\n",
      "Iteration 1800, generator loss: 1.738809, discriminator loss: 1.047669\n",
      "Iteration 1900, generator loss: 1.266870, discriminator loss: 1.048006\n",
      "Iteration 2000, generator loss: 1.471058, discriminator loss: 0.945770\n",
      "Iteration 2100, generator loss: 1.304263, discriminator loss: 0.834187\n",
      "Iteration 2200, generator loss: 1.093135, discriminator loss: 1.039909\n",
      "Iteration 2300, generator loss: 1.330685, discriminator loss: 0.801333\n",
      "Iteration 2400, generator loss: 1.507489, discriminator loss: 0.904154\n",
      "Iteration 2500, generator loss: 0.859542, discriminator loss: 1.497886\n",
      "Iteration 2600, generator loss: 0.919618, discriminator loss: 1.526368\n",
      "Iteration 2700, generator loss: 1.037918, discriminator loss: 0.992149\n",
      "Iteration 2800, generator loss: 1.041386, discriminator loss: 1.141172\n",
      "Iteration 2900, generator loss: 1.060087, discriminator loss: 1.031029\n",
      "Iteration 3000, generator loss: 1.225866, discriminator loss: 1.063918\n",
      "Iteration 3100, generator loss: 1.236982, discriminator loss: 0.937058\n",
      "Iteration 3200, generator loss: 1.231930, discriminator loss: 1.077761\n",
      "Iteration 3300, generator loss: 1.334498, discriminator loss: 1.098132\n",
      "Iteration 3400, generator loss: 1.122563, discriminator loss: 1.045714\n",
      "Iteration 3500, generator loss: 1.219206, discriminator loss: 0.980297\n",
      "Iteration 3600, generator loss: 1.002795, discriminator loss: 1.166191\n",
      "Iteration 3700, generator loss: 1.365536, discriminator loss: 0.905591\n",
      "---Read All Epochs---\n",
      "---Training Ends---\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 32\n",
    "max_iter = 500000\n",
    "x_batch = get_batch(train_images, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    n_iter = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        while n_iter < max_iter:\n",
    "            random_noise = np.random.normal(size=(batch_size, noise_dim))\n",
    "            real_images = sess.run(x_batch)\n",
    "            loss1, _ = sess.run([gen_loss, gen_train], {noise: random_noise})\n",
    "            loss2, _ = sess.run([dis_loss, dis_train], \n",
    "                                {noise: random_noise, targets: real_images})\n",
    "            if n_iter%100 == 0:\n",
    "                print('Iteration %d, generator loss: %f, discriminator loss: %f' \n",
    "                      %(n_iter, loss1, loss2))\n",
    "            n_iter += 1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('---Read All Epochs---')\n",
    "    print('---Training Ends---')\n",
    "    saver.save(sess, 'checkpoints/DCGAN.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/DCGAN.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    random_noise = np.random.normal(size=(1, noise_dim))\n",
    "    temp = sess.run(generated_images, {noise: random_noise})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181fbd2a90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(temp[0, :, :, 0]*127.5+127.5, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only after 2 epochs, we can see that the generated images looks something like real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
